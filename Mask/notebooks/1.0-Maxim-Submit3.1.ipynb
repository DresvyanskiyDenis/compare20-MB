{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import pandas as pd\n",
    "import re\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running ComParE2020_Mask BoAW-2000 baseline ... (this might take a while) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "from utils.configuration_utils import create_logger\n",
    "\n",
    "create_logger('.', 'BaselineV1.4.log', console_level=logging.INFO, file_level=logging.NOTSET)\n",
    "\n",
    "# Task\n",
    "task_name = 'ComParE2020_Mask'  # os.getcwd().split('/')[-2]\n",
    "classes = ['clear', 'mask']\n",
    "\n",
    "# Enter your team name HERE\n",
    "team_name = 'baseline'\n",
    "\n",
    "# Enter your submission number HERE\n",
    "submission_index = 1\n",
    "\n",
    "# Option\n",
    "show_confusion = True  # Display confusion matrix on devel\n",
    "\n",
    "# Configuration\n",
    "feature_set = 'BoAW-2000'  # For all available options, see the dictionary feat_conf\n",
    "# complexities = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0]  # SVM complexities (linear kernel)\n",
    "\n",
    "# Mapping each available feature set to tuple\n",
    "# (number of features, offset/index of first feature, separator, header option)\n",
    "feat_conf = {'ComParE': (6373, 1, ';', 'infer'),\n",
    "             'BoAW-125': (250, 1, ';', None),\n",
    "             'BoAW-250': (500, 1, ';', None),\n",
    "             'BoAW-500': (1000, 1, ';', None),\n",
    "             'BoAW-1000': (2000, 1, ';', None),\n",
    "             'BoAW-2000': (4000, 1, ';', None),\n",
    "             'auDeep-30': (1024, 2, ',', 'infer'),\n",
    "             'auDeep-45': (1024, 2, ',', 'infer'),\n",
    "             'auDeep-60': (1024, 2, ',', 'infer'),\n",
    "             'auDeep-75': (1024, 2, ',', 'infer'),\n",
    "             'auDeep-fused': (4096, 2, ',', 'infer'),\n",
    "             'DeepSpectrum_resnet50': (2048, 1, ',', 'infer')}\n",
    "\n",
    "num_feat = feat_conf[feature_set][0]\n",
    "ind_off = feat_conf[feature_set][1]\n",
    "sep = feat_conf[feature_set][2]\n",
    "header = feat_conf[feature_set][3]\n",
    "\n",
    "# Path of the features and labels\n",
    "features_path = '/media/maxim/SStorage/ComParE2020_Mask/features/'\n",
    "label_file = '/media/maxim/SStorage/ComParE2020_Mask/lab/labels.csv'\n",
    "\n",
    "# Start\n",
    "print('\\nRunning ' + task_name + ' ' + feature_set + ' baseline ... (this might take a while) \\n')\n",
    "\n",
    "# Load features and labels\n",
    "x_train = pd.read_csv(features_path + task_name + '.' + feature_set + '.train.csv', sep=sep, header=header,\n",
    "                      usecols=range(ind_off, num_feat + ind_off), dtype=np.float32).values\n",
    "x_devel = pd.read_csv(features_path + task_name + '.' + feature_set + '.devel.csv', sep=sep, header=header,\n",
    "                      usecols=range(ind_off, num_feat + ind_off), dtype=np.float32).values\n",
    "x_test = pd.read_csv(features_path + task_name + '.' + feature_set + '.test.csv', sep=sep, header=header,\n",
    "                     usecols=range(ind_off, num_feat + ind_off), dtype=np.float32).values\n",
    "\n",
    "df_labels = pd.read_csv(label_file)\n",
    "y_train = df_labels['label'][df_labels['file_name'].str.startswith('train')].values\n",
    "y_devel = df_labels['label'][df_labels['file_name'].str.startswith('devel')].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "train_indexes = np.arange(0, len(y_train))\n",
    "valid_indexes = np.arange(len(y_train), len(y_devel) + len(y_train))\n",
    "\n",
    "splits = []\n",
    "\n",
    "# valid\n",
    "valid_skf = StratifiedKFold(n_splits=2, random_state=12, shuffle=True)\n",
    "valid_splits = valid_skf.split(np.zeros(len(y_devel)), np.asarray(y_devel))\n",
    "for i, (t, v) in enumerate(valid_splits):\n",
    "    v_t = valid_indexes[t]\n",
    "    v_v = valid_indexes[v]\n",
    "    splits.append((np.hstack((train_indexes, v_t)), v_v))\n",
    "    \n",
    "# train\n",
    "train_skf = StratifiedKFold(n_splits=2, random_state=12, shuffle=True)\n",
    "train_splits = train_skf.split(np.zeros(len(y_train)), np.asarray(y_train))\n",
    "for i, (t, v) in enumerate(train_splits):\n",
    "    t_t = train_indexes[t]\n",
    "    t_v = train_indexes[v]\n",
    "    splits.append((np.hstack((t_t, valid_indexes)), t_v))\n",
    "\n",
    "all_x = np.vstack((x_train, x_devel))\n",
    "all_y = np.hstack((y_train, y_devel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-26 09:33:51,261:INFO:Start Logging\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "logging.info('Start Logging')\n",
    "\n",
    "for i, (t_indexes, d_indexes) in enumerate(splits):\n",
    "    train_subset_x, devel_subset_x = all_x[t_indexes], all_x[d_indexes]\n",
    "    train_subset_y, devel_subset_y = all_y[t_indexes], all_y[d_indexes]\n",
    "    \n",
    "    # Feature normalisation\n",
    "    scaler = MinMaxScaler()\n",
    "    train_subset_x = scaler.fit_transform(train_subset_x)\n",
    "    devel_subset_x = scaler.transform(devel_subset_x)\n",
    "    \n",
    "    clf = svm.SVC(random_state=0, probability=True)\n",
    "    clf.fit(train_subset_x, train_subset_y)\n",
    "    y_pred = clf.predict(devel_subset_x)\n",
    "    uar_score = recall_score(devel_subset_y, y_pred, labels=classes, average='macro')\n",
    "    logging.info('UAR on Devel {0}'.format(uar_score * 100))\n",
    "    if show_confusion:\n",
    "        logging.info('Confusion matrix (Devel):')\n",
    "        logging.info(classes)\n",
    "        logging.info(confusion_matrix(devel_subset_y, y_pred, labels=classes))\n",
    "\n",
    "    # Train SVM model on the whole training data with optimum complexity and get predictions on test data\n",
    "    logging.info('\\nFOLD {0}. UAR on Devel {1:.1f}\\n'.format(i, uar_score * 100))\n",
    "    \n",
    "    joblib.dump(scaler, '{0}_scaler_fold_{1}.model'.format(feature_set, i))\n",
    "    joblib.dump(clf, '{0}_cls_fold_{1}.model'.format(feature_set, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', color_map=plt.cm.Blues, fig_path=None):\n",
    "        \"\"\"\n",
    "        This function prints and plots the confusion matrix,\n",
    "        Normalization can be applied by setting `normalize=True`\n",
    "        \"\"\"\n",
    "        if not title:\n",
    "            if normalize:\n",
    "                title = 'Normalized confusion matrix'\n",
    "            else:\n",
    "                title = 'Confusion matrix, without normalization'\n",
    "\n",
    "            # Compute confusion matrix\n",
    "        # Only use the labels that appear in the data\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print(\"Normalized confusion matrix\")\n",
    "        else:\n",
    "            print('Confusion matrix, without normalization')\n",
    "\n",
    "        np.set_printoptions(precision=3)\n",
    "        print(cm)\n",
    "        np.set_printoptions(precision=6)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        im = ax.imshow(cm, interpolation='nearest', cmap=color_map)\n",
    "        ax.figure.colorbar(im, ax=ax)\n",
    "        # We want to show all ticks...\n",
    "        ax.set(xticks=np.arange(cm.shape[1]),\n",
    "               yticks=np.arange(cm.shape[0]),\n",
    "               xticklabels=classes, yticklabels=classes,\n",
    "               title=title,\n",
    "               ylabel='True label',\n",
    "               xlabel='Predicted label')\n",
    "\n",
    "#         ax.set_xticks(np.arange(cm.shape[1] + 1)-.5)\n",
    "#         ax.set_yticks(np.arange(cm.shape[0] + 1)-.5)\n",
    "\n",
    "        # Rotate the tick labels and set their alignment.\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "                 rotation_mode=\"anchor\")\n",
    "\n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        fmt = '.2f' if normalize else 'd'\n",
    "        thresh = cm.max() / 2.\n",
    "        for i in range(cm.shape[0]):\n",
    "            for j in range(cm.shape[1]):\n",
    "                ax.text(j, i, format(cm[i, j], fmt),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        if fig_path:\n",
    "            plt.savefig(fig_path)\n",
    "        else:\n",
    "            plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Validation\n",
      "Validating Fold 0\n",
      "Validating Fold 1\n",
      "Validating Fold 2\n",
      "Validating Fold 3\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "print('Start Validation')\n",
    "\n",
    "all_test_predictions = []\n",
    "all_test_labels = []\n",
    "for i, (t_indexes, d_indexes) in enumerate(splits):\n",
    "    print('Validating Fold {0}'.format(i))\n",
    "    fold_labels = []\n",
    "    fold_predictions = []\n",
    "    \n",
    "    train_subset_x, devel_subset_x = all_x[t_indexes], all_x[d_indexes]\n",
    "    train_subset_y, devel_subset_y = all_y[t_indexes], all_y[d_indexes]\n",
    "    \n",
    "    # Feature normalisation\n",
    "    scaler = joblib.load('{0}_scaler_fold_{1}.model'.format(feature_set, i))\n",
    "    train_subset_x = scaler.transform(train_subset_x)\n",
    "    devel_subset_x = scaler.transform(devel_subset_x)\n",
    "    clf = joblib.load('{0}_cls_fold_{1}.model'.format(feature_set, i))\n",
    "    y_pred = clf.predict_proba(devel_subset_x)\n",
    "\n",
    "    all_test_labels.append(np.asarray(devel_subset_y))\n",
    "    all_test_predictions.append(np.asarray(y_pred))\n",
    "    \n",
    "#     print('UAR on Devel {0}'.format(uar_score * 100))\n",
    "#     if show_confusion:\n",
    "#         print('Confusion matrix (Devel):')\n",
    "#         print(classes)\n",
    "#         cm = confusion_matrix(devel_subset_y, y_pred, labels=classes)\n",
    "#         print(cm)\n",
    "#         res_name = '{0}_fold_{1}'.format(feature_set, i)       \n",
    "#        plot_confusion_matrix(cm=cm, classes=classes, normalize=True, \n",
    "#                               title='{}.png'.format(res_name), fig_path='{}.png'.format(res_name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 4):\n",
    "    str_to_int = {\n",
    "        'clear': 0,\n",
    "        'mask': 1,\n",
    "    }\n",
    "\n",
    "    int_labels = np.asarray([str_to_int[i] for i in all_test_labels[i]])\n",
    "    res = np.concatenate((all_test_predictions[i], np.expand_dims(int_labels, axis=1)), axis=1)\n",
    "    np.savetxt(\"subm3(svm)_devel_preds_{}.csv\".format(i), res, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Testing\n",
      "Testing Fold 0\n",
      "Testing Fold 1\n",
      "Testing Fold 2\n",
      "Testing Fold 3\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "print('Start Testing')\n",
    "\n",
    "all_test_predictions = []\n",
    "for i, (t_indexes, d_indexes) in enumerate(splits):\n",
    "    print('Testing Fold {0}'.format(i))\n",
    "    # Feature normalisation\n",
    "    scaler = joblib.load('{0}_scaler_fold_{1}.model'.format(feature_set, i))\n",
    "    test_subset_x = scaler.transform(x_test)\n",
    "    clf = joblib.load('{0}_cls_fold_{1}.model'.format(feature_set, i))\n",
    "    y_pred = clf.predict_proba(test_subset_x)\n",
    "\n",
    "    all_test_predictions.append(y_pred)\n",
    "\n",
    "np.savetxt(\"subm3(svm)_test_preds.csv\", np.concatenate(all_test_predictions, axis=1), delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlenv)",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}